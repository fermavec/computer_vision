{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3690e07-0870-4f21-acc0-16093740aebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para este ejemplo usaremos el dataset de open images\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5215e9e3-f295-4586-b874-44ec6704bea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ta = pd.read_csv('../01_ML-CV/Open_Images_Data/test-annotations-bbox.csv')\n",
    "ti = pd.read_csv('../01_ML-CV/Open_Images_Data/test-images.csv')\n",
    "va = pd.read_csv('../01_ML-CV/Open_Images_Data/validation-annotations-bbox.csv')\n",
    "vi = pd.read_csv('../01_ML-CV/Open_Images_Data/validation-images.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50006b0-f0ca-458f-9cf9-9892f3b0aec0",
   "metadata": {},
   "source": [
    "## Datasets Utilizados\n",
    "\n",
    "### Test Annotations (ta)\n",
    "**Descripción**: Contiene las anotaciones de las cajas delimitadoras (bounding boxes) para las imágenes de prueba.\n",
    "**Uso**: Se utiliza para evaluar el rendimiento del modelo de detección y clasificación de objetos en un conjunto de datos no visto durante el entrenamiento.\n",
    "\n",
    "### Test Images (ti)\n",
    "**Descripción**: Contiene una lista de imágenes de prueba.\n",
    "**Uso**: Se utiliza para obtener las imágenes que serán evaluadas con las anotaciones correspondientes en el dataset de prueba.\n",
    "\n",
    "### Validation Annotations (va)\n",
    "**Descripción**: Contiene las anotaciones de las cajas delimitadoras (bounding boxes) para las imágenes de validación.\n",
    "**Uso**: Se utiliza para validar el modelo durante su desarrollo, permitiendo ajustar hiperparámetros y mejorar la precisión del modelo.\n",
    "\n",
    "### Validation Images (vi)\n",
    "**Descripción**: Contiene una lista de imágenes de validación.\n",
    "**Uso**: Se utiliza para obtener las imágenes que serán validadas con las anotaciones correspondientes en el dataset de validación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbf5abd-b7ef-4e10-bdbe-c9eab2da2060",
   "metadata": {},
   "source": [
    "# Paso 1: Inspeccionar los Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c15b1911-0f45-472c-853b-be6b0d139b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Images (ti):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125436 entries, 0 to 125435\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   ImageID             125436 non-null  object\n",
      " 1   Subset              125436 non-null  object\n",
      " 2   OriginalURL         125436 non-null  object\n",
      " 3   OriginalLandingURL  125436 non-null  object\n",
      " 4   License             125436 non-null  object\n",
      " 5   AuthorProfileURL    125436 non-null  object\n",
      " 6   Author              125436 non-null  object\n",
      " 7   Title               125436 non-null  object\n",
      " 8   OriginalSize        125436 non-null  int64 \n",
      " 9   OriginalMD5         125436 non-null  object\n",
      " 10  Thumbnail300KURL    120869 non-null  object\n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 10.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Información general del dataset de imágenes de prueba\n",
    "print(\"Test Images (ti):\")\n",
    "print(ti.info())\n",
    "#print(ti.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88ad18cf-0b5f-40de-8261-cae45e46beb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Images (ta):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 625282 entries, 0 to 625281\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   ImageID      625282 non-null  object \n",
      " 1   Source       625282 non-null  object \n",
      " 2   LabelName    625282 non-null  object \n",
      " 3   Confidence   625282 non-null  int64  \n",
      " 4   XMin         625282 non-null  float64\n",
      " 5   XMax         625282 non-null  float64\n",
      " 6   YMin         625282 non-null  float64\n",
      " 7   YMax         625282 non-null  float64\n",
      " 8   IsOccluded   625282 non-null  int64  \n",
      " 9   IsTruncated  625282 non-null  int64  \n",
      " 10  IsGroupOf    625282 non-null  int64  \n",
      " 11  IsDepiction  625282 non-null  int64  \n",
      " 12  IsInside     625282 non-null  int64  \n",
      "dtypes: float64(4), int64(6), object(3)\n",
      "memory usage: 62.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Información general del dataset de imágenes de prueba\n",
    "print(\"Test Images (ta):\")\n",
    "print(ta.info())\n",
    "#print(ta.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07e3d501-cb6c-4fbd-a16d-809b81ff495f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Images (vi):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41620 entries, 0 to 41619\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   ImageID             41620 non-null  object\n",
      " 1   Subset              41620 non-null  object\n",
      " 2   OriginalURL         41620 non-null  object\n",
      " 3   OriginalLandingURL  41620 non-null  object\n",
      " 4   License             41620 non-null  object\n",
      " 5   AuthorProfileURL    41620 non-null  object\n",
      " 6   Author              41620 non-null  object\n",
      " 7   Title               41620 non-null  object\n",
      " 8   OriginalSize        41620 non-null  int64 \n",
      " 9   OriginalMD5         41620 non-null  object\n",
      " 10  Thumbnail300KURL    40100 non-null  object\n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 3.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Información general del dataset de imágenes de prueba\n",
    "print(\"Test Images (vi):\")\n",
    "print(vi.info())\n",
    "#print(vi.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5894f285-3149-4601-bd38-67e2231603dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Images (va):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 204621 entries, 0 to 204620\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   ImageID      204621 non-null  object \n",
      " 1   Source       204621 non-null  object \n",
      " 2   LabelName    204621 non-null  object \n",
      " 3   Confidence   204621 non-null  int64  \n",
      " 4   XMin         204621 non-null  float64\n",
      " 5   XMax         204621 non-null  float64\n",
      " 6   YMin         204621 non-null  float64\n",
      " 7   YMax         204621 non-null  float64\n",
      " 8   IsOccluded   204621 non-null  int64  \n",
      " 9   IsTruncated  204621 non-null  int64  \n",
      " 10  IsGroupOf    204621 non-null  int64  \n",
      " 11  IsDepiction  204621 non-null  int64  \n",
      " 12  IsInside     204621 non-null  int64  \n",
      "dtypes: float64(4), int64(6), object(3)\n",
      "memory usage: 20.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Información general del dataset de imágenes de prueba\n",
    "print(\"Test Images (va):\")\n",
    "print(va.info())\n",
    "#print(ti.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1248a3f2-038b-41ec-b312-a225813483f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:\n",
      "(125436, 11)\n",
      "(625282, 13)\n",
      "(41620, 11)\n",
      "(204621, 13)\n"
     ]
    }
   ],
   "source": [
    "# Tamaño\n",
    "print(\"Shape:\")\n",
    "print(ti.shape)\n",
    "print(ta.shape)\n",
    "print(vi.shape)\n",
    "print(va.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c396f32-7adc-46a6-a251-89592949b1d8",
   "metadata": {},
   "source": [
    "# Paso 2. Ajustar inconsistencias\n",
    "- en este caso tenemos un buen volumen de datos sin valores nulos por lo que solo será necesario eliminar duplicados. Dependiendo la situación y el contexto de los datos, será la toma de la mejor decisión para ajustar. Puedes eliminar nulos, trabajar con medidas de tendencia central u otras para complementar la información, entore otras estrategias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5673a81f-42b0-4f66-a0f0-22f5e6103b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicados eliminados en Test Annotations: 0 filas eliminadas\n"
     ]
    }
   ],
   "source": [
    "initial_shape_ta = ta.shape\n",
    "ta = ta.drop_duplicates()\n",
    "print(f\"Duplicados eliminados en Test Annotations: {initial_shape_ta[0] - ta.shape[0]} filas eliminadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a6eb394-962f-45da-b70b-59a8c5706731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicados eliminados en Test Imagess: 0 filas eliminadas\n"
     ]
    }
   ],
   "source": [
    "initial_shape_ti = ti.shape\n",
    "ti = ti.drop_duplicates()\n",
    "print(f\"Duplicados eliminados en Test Imagess: {initial_shape_ti[0] - ti.shape[0]} filas eliminadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b591078-8582-4ede-867e-d9d936145bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicados eliminados en Validation Images: 0 filas eliminadas\n"
     ]
    }
   ],
   "source": [
    "initial_shape_vi = vi.shape\n",
    "vi = vi.drop_duplicates()\n",
    "print(f\"Duplicados eliminados en Validation Images: {initial_shape_vi[0] - vi.shape[0]} filas eliminadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f55e3e2-fc0e-4b6f-a87b-8760a35775d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicados eliminados en Validation Annotations: 0 filas eliminadas\n"
     ]
    }
   ],
   "source": [
    "initial_shape_va = va.shape\n",
    "va = va.drop_duplicates()\n",
    "print(f\"Duplicados eliminados en Validation Annotations: {initial_shape_va[0] - va.shape[0]} filas eliminadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c9eaf4-b668-4aa8-8eeb-2341c25fb7d3",
   "metadata": {},
   "source": [
    "# Paso 3. Normalización de las Coordenadas de las Cajas Delimitadoras\n",
    "- Para la normalización, utilizaremos MinMaxScaler de sklearn.preprocessing para escalar las coordenadas de las cajas delimitadoras\n",
    "- - Dado que estamos trabajando con detección de objetos y los datasets contienen coordenadas de cajas delimitadoras (bounding boxes), es importante asegurarnos de que estas coordenadas estén en un rango consistente, como [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f257337e-5c0c-479b-9312-9f6e3382a760",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_ta = MinMaxScaler()\n",
    "ta[['XMin', 'XMax', 'YMin', 'YMax']] = scaler_ta.fit_transform(ta[['XMin', 'XMax', 'YMin', 'YMax']])\n",
    "\n",
    "scaler_va = MinMaxScaler()\n",
    "va[['XMin', 'XMax', 'YMin', 'YMax']] = scaler_va.fit_transform(va[['XMin', 'XMax', 'YMin', 'YMax']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6282753-4b60-495a-956e-93a4d7c1b764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Annotations (ta) después de la normalización:\n",
      "                XMin           XMax           YMin           YMax\n",
      "count  625282.000000  625282.000000  625282.000000  625282.000000\n",
      "mean        0.341017       0.660734       0.310061       0.668117\n",
      "std         0.282472       0.281995       0.242598       0.273722\n",
      "min         0.000000       0.000000       0.000000       0.000000\n",
      "25%         0.077114       0.445438       0.102359       0.445661\n",
      "50%         0.301111       0.700295       0.276068       0.703701\n",
      "75%         0.556324       0.925448       0.481004       0.928981\n",
      "max         1.000000       1.000000       1.000000       1.000000\n",
      "Validation Annotations (va) después de la normalización:\n",
      "                XMin           XMax           YMin           YMax\n",
      "count  204621.000000  204621.000000  204621.000000  204621.000000\n",
      "mean        0.340179       0.662969       0.308269       0.668580\n",
      "std         0.282275       0.281285       0.242079       0.274952\n",
      "min         0.000000       0.000000       0.000000       0.000000\n",
      "25%         0.076852       0.449223       0.099919       0.444271\n",
      "50%         0.299991       0.702741       0.274574       0.705689\n",
      "75%         0.554808       0.926969       0.478388       0.931681\n",
      "max         1.000000       1.000000       1.000000       1.000000\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Annotations (ta) después de la normalización:\")\n",
    "print(ta[['XMin', 'XMax', 'YMin', 'YMax']].describe())\n",
    "\n",
    "print(\"Validation Annotations (va) después de la normalización:\")\n",
    "print(va[['XMin', 'XMax', 'YMin', 'YMax']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7acd6f-5d66-4f96-af0c-17e5926607f1",
   "metadata": {},
   "source": [
    "# Paso 4. Verificar y Manejar Cualquier Otra Inconsistencia\n",
    "- Dado que ya hemos cargado los datos, inspeccionado su estructura, eliminado duplicados y normalizado las coordenadas de las cajas delimitadoras, el siguiente paso es verificar y manejar cualquier otra inconsistencia que pueda existir en los datos. Esto puede incluir:\n",
    "1. Verificar la coherencia de las etiquetas de clase: Asegurarse de que todas las etiquetas de clase sean válidas y consistentes.\n",
    "2. Asegurar que todas las imágenes tengan anotaciones correspondientes: Asegurar que no haya imágenes sin anotaciones y viceversa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3a0b7ec-3d11-4de1-9e5f-79ea7099bebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiquetas de clase en Test Annotations:\n",
      "['/m/07j7r' '/m/015p6' '/m/05s2s' '/m/07yv9' '/m/0k4j' '/m/01g317'\n",
      " '/m/0283dt1' '/m/03q69' '/m/04hgtk' '/m/05r655' '/m/09j2d' '/m/0dzct'\n",
      " '/m/0dzf4' '/m/0c9ph5' '/m/0k0pj' '/m/0cgh4' '/m/018xm' '/m/09b5t'\n",
      " '/m/05zsy' '/m/0dv77' '/m/03120' '/m/01_bhs' '/m/02y6n' '/m/0270h'\n",
      " '/m/0284d' '/m/0cxn2' '/m/0138tl' '/m/083kb' '/m/02p0tk3' '/m/035r7c'\n",
      " '/m/04yx4' '/m/05y5lj' '/m/01d40f' '/m/01lcw4' '/m/03bt1vf' '/m/07r04'\n",
      " '/m/083wq' '/m/08dz3q' '/m/0d4v4' '/m/0h9mv' '/m/015h_t' '/m/02wbm'\n",
      " '/m/0bt9lr' '/m/03vt0' '/m/09kmb' '/m/01h3n' '/m/0cyhj_' '/m/04bcr3'\n",
      " '/m/0c_jw' '/m/02xwb' '/m/09kx5' '/m/01r546' '/m/05z55' '/m/01xq0k1'\n",
      " '/m/04rky' '/m/09j5n' '/m/0cnyhnx' '/m/04_sv' '/m/0zvk5' '/m/01prls'\n",
      " '/m/052lwg6' '/m/0l515' '/m/01xyhv' '/m/01mzpv' '/m/0k65p' '/m/02dl1y'\n",
      " '/m/0463sg' '/m/0kpqd' '/m/01jfm_' '/m/0199g' '/m/0bjyj5' '/m/014j1m'\n",
      " '/m/05n4y' '/m/06c54' '/m/014sv8' '/m/039xj_' '/m/019jd' '/m/07mhn'\n",
      " '/m/01xs3r' '/m/076bq' '/m/0ch_cf' '/m/04c0y' '/m/019dx1' '/m/0h99cwc'\n",
      " '/m/0h23m' '/m/0n28_' '/m/01yx86' '/m/03k3r' '/m/0jqgx' '/m/0d5gx'\n",
      " '/m/025dyy' '/m/0cmf2' '/m/0f4s2w' '/m/0hnnb' '/m/02pkr5' '/m/09g1w'\n",
      " '/m/01bqk0' '/m/03p3bw' '/m/017ftj' '/m/0342h' '/m/01n4qj' '/m/01226z'\n",
      " '/m/07y_7' '/m/09qck' '/m/01bl7v' '/m/0jyfg' '/m/02zn6n' '/m/03hl4l9'\n",
      " '/m/014trl' '/m/050k8' '/m/0bh9flk' '/m/0271t' '/m/04dr76w' '/m/0h8mhzd'\n",
      " '/m/01gkx_' '/m/079cl' '/m/02s195' '/m/054fyh' '/m/08hvt4' '/m/0fszt'\n",
      " '/m/03ssj5' '/m/0c06p' '/m/0242l' '/m/03xxp' '/m/01yrx' '/m/034c16'\n",
      " '/m/03jm5' '/m/078n6m' '/m/07c52' '/m/09728' '/m/0jbk' '/m/01599'\n",
      " '/m/024g6' '/m/024d2' '/m/0fly7' '/m/04brg2' '/m/01ww8y' '/m/05_5p_0'\n",
      " '/m/01lrl' '/m/052sf' '/m/01fh4r' '/m/03s_tn' '/m/0by6g' '/m/0jg57'\n",
      " '/m/07v9_z' '/m/01j51' '/m/0cyfs' '/m/0hg7b' '/m/07cmd' '/m/01b638'\n",
      " '/m/06msq' '/m/0hqkz' '/m/0qmmr' '/m/0dtln' '/m/0306r' '/m/0k5j'\n",
      " '/m/01fb_0' '/m/0jy4k' '/m/027pcv' '/m/0grw1' '/m/031n1' '/m/03nfch'\n",
      " '/m/06k2mb' '/m/02dgv' '/m/08p92x' '/m/0b_rs' '/m/07030' '/m/09tvcd'\n",
      " '/m/04m9y' '/m/0k1tl' '/m/01dxs' '/m/02rgn06' '/m/02zvsm' '/m/026qbn5'\n",
      " '/m/03m3pdh' '/m/0703r8' '/m/0cyf8' '/m/0130jx' '/m/01s105' '/m/0fqfqc'\n",
      " '/m/0h2r6' '/m/07crc' '/m/013y1f' '/m/0898b' '/m/06nwz' '/m/081qc'\n",
      " '/m/01y9k5' '/m/033cnk' '/m/020jm' '/m/02rdsp' '/m/078jl' '/m/0l14j_'\n",
      " '/m/031b6r' '/m/04tn4x' '/m/04szw' '/m/057cc' '/m/05r5c' '/m/0220r2'\n",
      " '/m/02p5f1q' '/m/02vqfm' '/m/07clx' '/m/03rszm' '/m/03fwl' '/m/0fm3zh'\n",
      " '/m/0c568' '/m/0cl4p' '/m/0czz2' '/m/01tcjp' '/m/06m11' '/m/07gql'\n",
      " '/m/03bbps' '/m/01fdzj' '/m/01bfm9' '/m/06_fw' '/m/02z51p' '/m/05kyg_'\n",
      " '/m/03fp41' '/m/06mf6' '/m/07k1x' '/m/03c7gz' '/m/029bxz' '/m/01dy8n'\n",
      " '/m/02p3w7d' '/m/04vv5k' '/m/050gv4' '/m/099ssp' '/m/02fq_6' '/m/0h8n5zk'\n",
      " '/m/07jdr' '/m/08pbxl' '/m/040b_t' '/m/03qrc' '/m/0dv9c' '/m/01lynh'\n",
      " '/m/015qff' '/m/01mqdt' '/m/02522' '/m/09f_2' '/m/04ylt' '/m/06ncr'\n",
      " '/m/02hj4' '/m/084zz' '/m/0dftk' '/m/02_n6y' '/m/0c3mkw' '/m/096mb'\n",
      " '/m/0cydv' '/m/01nkt' '/m/0llzx' '/m/09k_b' '/m/0l3ms' '/m/0fj52s'\n",
      " '/m/02wv84t' '/m/0b3fp9' '/m/0fqt361' '/m/0fx9l' '/m/043nyj' '/m/016m2d'\n",
      " '/m/09d5_' '/m/01pns0' '/m/05vtc' '/m/07bgp' '/m/0663v' '/m/0crjs'\n",
      " '/m/0gjbg72' '/m/071p9' '/m/09csl' '/m/0f6wt' '/m/0bt_c3' '/m/06j2d'\n",
      " '/m/0ccs93' '/m/01bjv' '/m/068zj' '/m/0cjs7' '/m/09ct_' '/m/0d8zb'\n",
      " '/m/07qxg_' '/m/0pcr' '/m/01n5jq' '/m/01rzcn' '/m/04gth' '/m/0cn6p'\n",
      " '/m/0gd2v' '/m/0dbzx' '/m/0633h' '/m/01xygc' '/m/032b3c' '/m/0167gd'\n",
      " '/m/01xgg_' '/m/01m4t' '/m/0gj37' '/m/0ph39' '/m/04p0qw' '/m/01jfsr'\n",
      " '/m/0dt3t' '/m/05z6w' '/m/080hkjn' '/m/019h78' '/m/01f8m5' '/m/01432t'\n",
      " '/m/020kz' '/m/07c6l' '/m/03__z0' '/m/0pg52' '/m/09f20' '/m/026t6'\n",
      " '/m/01j61q' '/m/05kms' '/m/018p4k' '/m/06_72j' '/m/019w40' '/m/06z37_'\n",
      " '/m/015x4r' '/m/012w5l' '/m/02vkqh8' '/m/0642b4' '/m/011k07' '/m/06__v'\n",
      " '/m/0kpt_' '/m/01rkbr' '/m/02l8p9' '/m/04zpv' '/m/01d380' '/m/0cmx8'\n",
      " '/m/0268lbt' '/m/0kmg4' '/m/03q5c7' '/m/071qp' '/m/0dj6p' '/m/0nl46'\n",
      " '/m/0319l' '/m/01m2v' '/m/021sj1' '/m/02g30s' '/m/01gmv2' '/m/030610'\n",
      " '/m/029b3' '/m/061_f' '/m/0bwd_0j' '/m/047j0r' '/m/0d4w1' '/m/0174n1'\n",
      " '/m/03g8mr' '/m/03grzl' '/m/09ddx' '/m/0hdln' '/m/061hd_' '/m/01c648'\n",
      " '/m/025rp__' '/m/03q5t' '/m/0d_2m' '/m/0420v5' '/m/02gzp' '/m/04ctx'\n",
      " '/m/058qzx' '/m/03tw93' '/m/04169hn' '/m/03bk1' '/m/02f9f_' '/m/063rgb'\n",
      " '/m/04m6gz' '/m/0gm28' '/m/0hkxq' '/m/0dbvp' '/m/0388q' '/m/0f9_l'\n",
      " '/m/07fbm7' '/m/01z1kdw' '/m/074d1' '/m/07cx4' '/m/01lsmm' '/m/0dv5r'\n",
      " '/m/0jly1' '/m/0nybt' '/m/02x984l' '/m/05gqfk' '/m/01cmb2' '/m/01b7fy'\n",
      " '/m/01g3x7' '/m/07j87' '/m/03bj1' '/m/04rmv' '/m/01x_v' '/m/0ftb8'\n",
      " '/m/033rq4' '/m/0449p' '/m/0c29q' '/m/0cdl1' '/m/0cdn1' '/m/03m5k'\n",
      " '/m/0hnyx' '/m/0mkg' '/m/02crq1' '/m/09ld4' '/m/01llwg' '/m/0dq75'\n",
      " '/m/03hlz0c' '/m/014y4n' '/m/021mn' '/m/01nq26' '/m/03ldnb' '/m/0h8l4fh'\n",
      " '/m/0cffdh' '/m/01j3zr' '/m/06bt6' '/m/01vbnl' '/m/0fz0h' '/m/0271qf7'\n",
      " '/m/01krhy' '/m/0gxl3' '/m/04kkgm' '/m/0152hh' '/m/0hf58v5' '/m/0f6nr'\n",
      " '/m/02pv19' '/m/06y5r' '/m/06pcq' '/m/0gv1x' '/m/0176mf' '/m/02jvh9'\n",
      " '/m/0_cp5' '/m/04cp_' '/m/02jnhm' '/m/02jz0l' '/m/0h8nr_l' '/m/0p833'\n",
      " '/m/0120dh' '/m/047v4b' '/m/0ft9s' '/m/0mcx2' '/m/02d9qx' '/m/01s55n'\n",
      " '/m/06c7f7' '/m/02068x' '/m/0jwn_' '/m/07pj7bq' '/m/02ctlc' '/m/01gllr'\n",
      " '/m/0ll1f78' '/m/0qjjc' '/m/02xb7qb' '/m/0584n8' '/m/073bxn' '/m/01f91_'\n",
      " '/m/01h8tj' '/m/02wg_p' '/m/0mw_6' '/m/029tx' '/m/04yqq2' '/m/018j2'\n",
      " '/m/07xyvk' '/m/02wbtzl' '/m/09gys' '/m/07dm6' '/m/01b9xk' '/m/035vxb'\n",
      " '/m/02zt3' '/m/0h8my_4' '/m/01xqw' '/m/054_l' '/m/03fj2' '/m/012n7d'\n",
      " '/m/0cd4d' '/m/03dnzn' '/m/065h6l' '/m/02jfl0' '/m/02h19r' '/m/0wdt60w'\n",
      " '/m/0fldg' '/m/0174k2' '/m/01dwsz' '/m/0h8n6ft' '/m/0gd36' '/m/0fbdv'\n",
      " '/m/04g2r' '/m/01x3z' '/m/0h8mzrc' '/m/01knjb' '/m/015wgc' '/m/046dlr'\n",
      " '/m/0gjkl' '/m/09rvcxw' '/m/02pjr4' '/m/03y6mg' '/m/01_5g' '/m/020lf'\n",
      " '/m/0fp6w' '/m/01kb5b' '/m/07dd4' '/m/01x3jk' '/m/06l9r' '/m/04y4h8h'\n",
      " '/m/03hj559' '/m/02wv6h6' '/m/084hf' '/m/0fbw6' '/m/0755b' '/m/0m53l'\n",
      " '/m/01hrv5' '/m/0cjq5' '/m/025nd' '/m/02pdsw' '/m/0lt4_' '/m/015qbp'\n",
      " '/m/0h8kx63' '/m/0_k2' '/m/015x5n' '/m/0djtd' '/m/01dws' '/m/012074'\n",
      " '/m/01j4z9' '/m/03txqz' '/m/0km7z' '/m/054xkw' '/m/06nrc' '/m/084rd'\n",
      " '/m/01h44' '/m/04v6l4' '/m/03kt2w' '/m/0162_1' '/m/0h8lkj8' '/m/01dwwc'\n",
      " '/m/03d443' '/m/04h7h' '/m/07kng9' '/m/0frqm' '/m/057p5t' '/m/025fsf'\n",
      " '/m/03v5tg' '/m/01940j' '/m/0323sq' '/m/044r5d' '/m/02lbcq' '/m/01k6s3'\n",
      " '/m/03qjg' '/m/012ysf' '/m/073g6' '/m/02w3r3' '/m/0dkzw' '/m/0h8n27j'\n",
      " '/m/09dzg' '/m/05ctyq' '/m/0d20w4' '/m/02tsc9' '/m/0h8n6f9' '/m/01btn'\n",
      " '/m/02w3_ws' '/m/03wym' '/m/012xff' '/m/02xqq' '/m/02wmf' '/m/0c3m8g'\n",
      " '/m/03jbxj' '/m/05bm6' '/m/0c2jj' '/m/09gtd' '/m/0h8ntjv' '/m/04f5ws'\n",
      " '/m/0f571' '/m/02x8cch' '/m/076lb9' '/m/05441v' '/m/0ky7b' '/m/0h8nm9j'\n",
      " '/m/04h8sr' '/m/0f8s22' '/m/02cvgx' '/m/05676x' '/m/0cqn2' '/m/0175cv'\n",
      " '/m/03wvsk' '/m/02fh7f' '/m/02vwcm' '/m/01j5ks' '/m/02d1br' '/m/03m3vtv']\n",
      "Etiquetas de clase en Validation Annotations:\n",
      "['/m/0cmf2' '/m/02wbm' '/m/02xwb' '/m/01g317' '/m/05y5lj' '/m/09j2d'\n",
      " '/m/09j5n' '/m/0dzf4' '/m/035r7c' '/m/04rky' '/m/07mhn' '/m/0bt9lr'\n",
      " '/m/03bt1vf' '/m/0k65p' '/m/0f4s2w' '/m/01z1kdw' '/m/083wq' '/m/0k4j'\n",
      " '/m/01bl7v' '/m/02p0tk3' '/m/03q69' '/m/04hgtk' '/m/0dzct' '/m/04yx4'\n",
      " '/m/05r655' '/m/05s2s' '/m/01_bhs' '/m/02y6n' '/m/052lwg6' '/m/0cdn1'\n",
      " '/m/0283dt1' '/m/08dz3q' '/m/0k0pj' '/m/04bcr3' '/m/0cgh4' '/m/01nkt'\n",
      " '/m/0c9ph5' '/m/04_sv' '/m/0h9mv' '/m/0jbk' '/m/071qp' '/m/03vt0'\n",
      " '/m/01s55n' '/m/025dyy' '/m/0n28_' '/m/01prls' '/m/07j7r' '/m/0bwd_0j'\n",
      " '/m/0271t' '/m/02jnhm' '/m/01lrl' '/m/04brg2' '/m/0c_jw' '/m/0fj52s'\n",
      " '/m/01jfm_' '/m/07yv9' '/m/0fm3zh' '/m/080hkjn' '/m/01f8m5' '/m/01xqw'\n",
      " '/m/07y_7' '/m/0_cp5' '/m/015x4r' '/m/01n4qj' '/m/0fly7' '/m/0138tl'\n",
      " '/m/0fszt' '/m/018xm' '/m/0199g' '/m/01bqk0' '/m/0h8mhzd' '/m/0zvk5'\n",
      " '/m/02pkr5' '/m/01yrx' '/m/0663v' '/m/0d8zb' '/m/0ch_cf' '/m/014sv8'\n",
      " '/m/05r5c' '/m/02p5f1q' '/m/02vqfm' '/m/01h8tj' '/m/02dgv' '/m/0d4v4'\n",
      " '/m/02522' '/m/07c52' '/m/019jd' '/m/019w40' '/m/01xs3r' '/m/04m9y'\n",
      " '/m/024g6' '/m/09k_b' '/m/01y9k5' '/m/04dr76w' '/m/0hg7b' '/m/04szw'\n",
      " '/m/0174n1' '/m/03grzl' '/m/01j51' '/m/0cyfs' '/m/01hrv5' '/m/07cmd'\n",
      " '/m/0270h' '/m/026t6' '/m/01gkx_' '/m/01gmv2' '/m/04g2r' '/m/0c29q'\n",
      " '/m/031n1' '/m/09b5t' '/m/026qbn5' '/m/02crq1' '/m/03jm5' '/m/078n6m'\n",
      " '/m/0b_rs' '/m/05z55' '/m/02dl1y' '/m/061hd_' '/m/0dq75' '/m/0306r'\n",
      " '/m/03k3r' '/m/0c06p' '/m/01ww8y' '/m/06msq' '/m/020jm' '/m/073bxn'\n",
      " '/m/0dv5r' '/m/050k8' '/m/0242l' '/m/0jqgx' '/m/09ld4' '/m/012074'\n",
      " '/m/01bjv' '/m/09kx5' '/m/0633h' '/m/03fp41' '/m/01226z' '/m/0grw1'\n",
      " '/m/01nq26' '/m/03nfch' '/m/0h2r6' '/m/03xxp' '/m/08pbxl' '/m/01lcw4'\n",
      " '/m/0cmx8' '/m/01llwg' '/m/07qxg_' '/m/0463sg' '/m/06c54' '/m/06nrc'\n",
      " '/m/0cdl1' '/m/01dxs' '/m/01rzcn' '/m/029b3' '/m/01n5jq' '/m/01d40f'\n",
      " '/m/02gzp' '/m/04ctx' '/m/015p6' '/m/02wv84t' '/m/0h99cwc' '/m/014y4n'\n",
      " '/m/06j2d' '/m/0ft9s' '/m/09tvcd' '/m/0ll1f78' '/m/01mqdt' '/m/0167gd'\n",
      " '/m/081qc' '/m/03120' '/m/0l515' '/m/03fwl' '/m/09f_2' '/m/047v4b'\n",
      " '/m/07r04' '/m/021mn' '/m/0h8mzrc' '/m/019h78' '/m/0cydv' '/m/09728'\n",
      " '/m/01xyhv' '/m/02zvsm' '/m/02p3w7d' '/m/0qmmr' '/m/011k07' '/m/0120dh'\n",
      " '/m/09dzg' '/m/052sf' '/m/04gth' '/m/032b3c' '/m/0bjyj5' '/m/02rdsp'\n",
      " '/m/07pj7bq' '/m/0by6g' '/m/016m2d' '/m/0449p' '/m/03fj2' '/m/054xkw'\n",
      " '/m/0gm28' '/m/0ccs93' '/m/015h_t' '/m/05z6w' '/m/0755b' '/m/0342h'\n",
      " '/m/02l8p9' '/m/0gd36' '/m/0cyf8' '/m/03bj1' '/m/06nwz' '/m/0fp6w'\n",
      " '/m/018p4k' '/m/0k5j' '/m/09ct_' '/m/0f6wt' '/m/0gv1x' '/m/01xgg_'\n",
      " '/m/01mzpv' '/m/021sj1' '/m/04169hn' '/m/07jdr' '/m/0p833' '/m/0dftk'\n",
      " '/m/03q5c7' '/m/07clx' '/m/05vtc' '/m/01bfm9' '/m/0cxn2' '/m/017ftj'\n",
      " '/m/06m11' '/m/0jyfg' '/m/09csl' '/m/09ddx' '/m/06pcq' '/m/01x_v'\n",
      " '/m/01pns0' '/m/06_72j' '/m/0hf58v5' '/m/01knjb' '/m/0174k2' '/m/0388q'\n",
      " '/m/01h3n' '/m/01xq0k1' '/m/0gd2v' '/m/029tx' '/m/083kb' '/m/0gxl3'\n",
      " '/m/01c648' '/m/03__z0' '/m/0bt_c3' '/m/0gjbg72' '/m/057cc' '/m/078jl'\n",
      " '/m/01x3z' '/m/0gjkl' '/m/0h23m' '/m/01dy8n' '/m/02zn6n' '/m/0cyhj_'\n",
      " '/m/039xj_' '/m/05_5p_0' '/m/0dv9c' '/m/040b_t' '/m/050gv4' '/m/099ssp'\n",
      " '/m/04c0y' '/m/0czz2' '/m/06__v' '/m/01599' '/m/02w3_ws' '/m/07bgp'\n",
      " '/m/0d_2m' '/m/0dbzx' '/m/0hkxq' '/m/079cl' '/m/06k2mb' '/m/0130jx'\n",
      " '/m/01s105' '/m/02jz0l' '/m/05kyg_' '/m/0b3fp9' '/m/0fqfqc' '/m/01b638'\n",
      " '/m/09kmb' '/m/027pcv' '/m/02cvgx' '/m/02hj4' '/m/01_5g' '/m/07030'\n",
      " '/m/01cmb2' '/m/01g3x7' '/m/01dwwc' '/m/0271qf7' '/m/0cjq5' '/m/07fbm7'\n",
      " '/m/058qzx' '/m/033cnk' '/m/04m6gz' '/m/03tw93' '/m/0284d' '/m/06c7f7'\n",
      " '/m/02_n6y' '/m/02pv19' '/m/044r5d' '/m/0fldg' '/m/07j87' '/m/06_fw'\n",
      " '/m/07k1x' '/m/0lt4_' '/m/0ftb8' '/m/03m3pdh' '/m/0703r8' '/m/015qff'\n",
      " '/m/0h8nr_l' '/m/0kpqd' '/m/0h8lkj8' '/m/071p9' '/m/01dws' '/m/02x984l'\n",
      " '/m/03ldnb' '/m/0642b4' '/m/0fbdv' '/m/01b9xk' '/m/0crjs' '/m/03bk1'\n",
      " '/m/0nybt' '/m/07c6l' '/m/07gql' '/m/0kmg4' '/m/02g30s' '/m/0319l'\n",
      " '/m/0k1tl' '/m/047j0r' '/m/014j1m' '/m/0f9_l' '/m/08hvt4' '/m/0d4w1'\n",
      " '/m/07kng9' '/m/04zpv' '/m/0898b' '/m/03hlz0c' '/m/0dt3t' '/m/03m5k'\n",
      " '/m/084zz' '/m/02fq_6' '/m/02wbtzl' '/m/05zsy' '/m/0fqt361' '/m/084rd'\n",
      " '/m/03hl4l9' '/m/0hnyx' '/m/013y1f' '/m/03q5t' '/m/01b7fy' '/m/0162_1'\n",
      " '/m/01jfsr' '/m/01fdzj' '/m/06z37_' '/m/01bms0' '/m/0jwn_' '/m/04vv5k'\n",
      " '/m/01yx86' '/m/04yqq2' '/m/014trl' '/m/0mkg' '/m/096mb' '/m/0cnyhnx'\n",
      " '/m/068zj' '/m/03ssj5' '/m/02zt3' '/m/04kkgm' '/m/0kpt_' '/m/01rkbr'\n",
      " '/m/01j61q' '/m/0ph39' '/m/03c7gz' '/m/02lbcq' '/m/046dlr' '/m/0h8n5zk'\n",
      " '/m/0hqkz' '/m/04h8sr' '/m/0268lbt' '/m/0cn6p' '/m/02068x' '/m/02wv6h6'\n",
      " '/m/06mf6' '/m/01krhy' '/m/0nl46' '/m/04tn4x' '/m/025rp__' '/m/0pcr'\n",
      " '/m/0220r2' '/m/01fh4r' '/m/03s_tn' '/m/054fyh' '/m/01lynh' '/m/012n7d'\n",
      " '/m/0mcx2' '/m/03jbxj' '/m/02s195' '/m/01vbnl' '/m/09g1w' '/m/03hj559'\n",
      " '/m/03kt2w' '/m/065h6l' '/m/019dx1' '/m/020kz' '/m/0jy4k' '/m/06y5r'\n",
      " '/m/02xb7qb' '/m/08p92x' '/m/02jfl0' '/m/0cffdh' '/m/03p3bw' '/m/09f20'\n",
      " '/m/0frqm' '/m/034c16' '/m/01gllr' '/m/0fz0h' '/m/01xygc' '/m/031b6r'\n",
      " '/m/057p5t' '/m/01tcjp' '/m/02f9f_' '/m/0dj6p' '/m/0pg52' '/m/01dwsz'\n",
      " '/m/0584n8' '/m/07dm6' '/m/0h8my_4' '/m/054_l' '/m/018j2' '/m/03dnzn'\n",
      " '/m/020lf' '/m/0h8l4fh' '/m/0hnnb' '/m/04cp_' '/m/06bt6' '/m/0gj37'\n",
      " '/m/0hdln' '/m/0djtd' '/m/024d2' '/m/0jly1' '/m/02rgn06' '/m/0cl4p'\n",
      " '/m/01h44' '/m/01m2v' '/m/0dbvp' '/m/01940j' '/m/03qrc' '/m/04rmv'\n",
      " '/m/0jg57' '/m/06ncr' '/m/029bxz' '/m/0fx9l' '/m/05n4y' '/m/015wgc'\n",
      " '/m/05gqfk' '/m/03d443' '/m/03bbps' '/m/01fb_0' '/m/01r546' '/m/030610'\n",
      " '/m/01j3zr' '/m/0fbw6' '/m/04v6l4' '/m/0m53l' '/m/02jvh9' '/m/07xyvk'\n",
      " '/m/0c568' '/m/02d9qx' '/m/0h8n6ft' '/m/03g8mr' '/m/0dtln' '/m/06l9r'\n",
      " '/m/01m4t' '/m/02xqq' '/m/04p0qw' '/m/0cd4d' '/m/02w3r3' '/m/09gtd'\n",
      " '/m/03v5tg' '/m/07crc' '/m/0152hh' '/m/0bh9flk' '/m/04h7h' '/m/025nd'\n",
      " '/m/0dv77' '/m/015x5n' '/m/09d5_' '/m/02pjr4' '/m/03y6mg' '/m/063rgb'\n",
      " '/m/03rszm' '/m/01432t' '/m/0l3ms' '/m/0d5gx' '/m/012xff' '/m/035vxb'\n",
      " '/m/061_f' '/m/07cx4' '/m/033rq4' '/m/02x8cch' '/m/0llzx' '/m/05676x'\n",
      " '/m/02vkqh8' '/m/02z51p' '/m/076bq' '/m/0176mf' '/m/01kb5b' '/m/09qck'\n",
      " '/m/01x3jk' '/m/09gys' '/m/07dd4' '/m/012w5l' '/m/04ylt' '/m/09rvcxw'\n",
      " '/m/05ctyq' '/m/0km7z' '/m/0l14j_' '/m/02wg_p' '/m/01lsmm' '/m/0cjs7'\n",
      " '/m/03txqz' '/m/074d1' '/m/0wdt60w' '/m/0323sq' '/m/0dkzw' '/m/01j5ks'\n",
      " '/m/015qbp' '/m/01f91_' '/m/02pdsw' '/m/05kms' '/m/04y4h8h' '/m/01btn'\n",
      " '/m/0qjjc' '/m/01k6s3' '/m/073g6' '/m/02h19r' '/m/043nyj' '/m/0_k2'\n",
      " '/m/02d1br' '/m/03m3vtv' '/m/0mw_6' '/m/02ctlc' '/m/0h8n27j' '/m/0h8kx63'\n",
      " '/m/0h8n6f9' '/m/0cqn2' '/m/0f6nr' '/m/0ky7b' '/m/02tsc9' '/m/0h8ntjv'\n",
      " '/m/01j4z9' '/m/01d380' '/m/0f571' '/m/0_dqb' '/m/084hf' '/m/076lb9'\n",
      " '/m/03l9g']\n"
     ]
    }
   ],
   "source": [
    "# Verificar etiquetas de clase en Test Annotations\n",
    "print(\"Etiquetas de clase en Test Annotations:\")\n",
    "print(ta['LabelName'].unique())\n",
    "\n",
    "# Verificar etiquetas de clase en Validation Annotations\n",
    "print(\"Etiquetas de clase en Validation Annotations:\")\n",
    "print(va['LabelName'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd9806a5-152f-40ef-9d3d-1149e3d86ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imágenes en Test sin anotaciones: 17277\n",
      "Imágenes en Validation sin anotaciones: 5695\n"
     ]
    }
   ],
   "source": [
    "# Verificar que todas las imágenes en test tengan anotaciones correspondientes\n",
    "test_image_ids = set(ti['ImageID'])\n",
    "test_annotation_ids = set(ta['ImageID'])\n",
    "\n",
    "# Imágenes sin anotaciones\n",
    "test_images_without_annotations = test_image_ids - test_annotation_ids\n",
    "print(f\"Imágenes en Test sin anotaciones: {len(test_images_without_annotations)}\")\n",
    "\n",
    "# Verificar que todas las imágenes en validation tengan anotaciones correspondientes\n",
    "validation_image_ids = set(vi['ImageID'])\n",
    "validation_annotation_ids = set(va['ImageID'])\n",
    "\n",
    "# Imágenes sin anotaciones\n",
    "validation_images_without_annotations = validation_image_ids - validation_annotation_ids\n",
    "print(f\"Imágenes en Validation sin anotaciones: {len(validation_images_without_annotations)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c688077-6f33-4e73-b158-134acb60871f",
   "metadata": {},
   "source": [
    "# Paso 5: Eliminar Imágenes sin Anotaciones\n",
    "- Vamos a eliminar las imágenes sin anotaciones de los datasets de prueba y validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7bfa823-4ad5-4434-9e6e-39a26fd60e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eliminadas 17277 imágenes sin anotaciones del dataset de prueba.\n",
      "Eliminadas 5695 imágenes sin anotaciones del dataset de validación.\n"
     ]
    }
   ],
   "source": [
    "# Eliminar imágenes sin anotaciones del dataset de imágenes de prueba\n",
    "if len(test_images_without_annotations) > 0:\n",
    "    ti = ti[~ti['ImageID'].isin(test_images_without_annotations)]\n",
    "    print(f\"Eliminadas {len(test_images_without_annotations)} imágenes sin anotaciones del dataset de prueba.\")\n",
    "\n",
    "# Eliminar imágenes sin anotaciones del dataset de imágenes de validación\n",
    "if len(validation_images_without_annotations) > 0:\n",
    "    vi = vi[~vi['ImageID'].isin(validation_images_without_annotations)]\n",
    "    print(f\"Eliminadas {len(validation_images_without_annotations)} imágenes sin anotaciones del dataset de validación.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92d0bfbb-c1cc-4792-a98e-1f4437b3e00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuevo tamaño del dataset de imágenes de prueba: (108159, 11)\n",
      "Nuevo tamaño del dataset de imágenes de validación: (35925, 11)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Nuevo tamaño del dataset de imágenes de prueba: {ti.shape}\")\n",
    "print(f\"Nuevo tamaño del dataset de imágenes de validación: {vi.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae447e9-6d16-435d-93be-44f47fa9b939",
   "metadata": {},
   "source": [
    "# Paso 6: Preparar los Datos para el Entrenamiento\n",
    "- Ahora vamos a preparar los datos para el entrenamiento. Este paso incluye: Guardar los Datasets Preprocesados: Guardar los datasets preprocesados en archivos CSV para su uso posterior en el entrenamiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4e721cd8-1d31-4ef7-9b51-c009902128cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets preprocesados guardados correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Guardar los datasets preprocesados en archivos CSV\n",
    "\n",
    "# Dataset de anotaciones de prueba\n",
    "ta.to_csv('../01_ML-CV/data/preprocessed_test_annotations.csv', index=False)\n",
    "\n",
    "# Dataset de imágenes de prueba\n",
    "ti.to_csv('../01_ML-CV/data/preprocessed_test_images.csv', index=False)\n",
    "\n",
    "# Dataset de anotaciones de validación\n",
    "va.to_csv('../01_ML-CV/data/preprocessed_validation_annotations.csv', index=False)\n",
    "\n",
    "# Dataset de imágenes de validación\n",
    "vi.to_csv('../01_ML-CV/data/preprocessed_validation_images.csv', index=False)\n",
    "\n",
    "print(\"Datasets preprocesados guardados correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09432fc7-0062-4eb7-a4e5-e646ddf1c109",
   "metadata": {},
   "source": [
    "# Preprocesamiento de Datos para el Asistente Inteligente de Navegación\n",
    "\n",
    "## Introducción\n",
    "\n",
    "El preprocesamiento de datos es una etapa crucial en el desarrollo de modelos de Machine Learning. Este proceso implica preparar y transformar los datos en un formato adecuado para que los algoritmos de Machine Learning puedan utilizarlos eficazmente. La calidad de los datos y cómo se preparan pueden tener un impacto significativo en el rendimiento y la precisión de los modelos.\n",
    "\n",
    "## Objetivos del Preprocesamiento\n",
    "\n",
    "1. **Mejorar la Calidad de los Datos**: Datos ruidosos, inconsistentes o incompletos pueden afectar negativamente el rendimiento del modelo. El preprocesamiento ayuda a limpiar y preparar los datos, mejorando su calidad.\n",
    "2. **Reducción de Sesgos**: Eliminar o corregir datos sesgados es crucial para evitar que el modelo aprenda patrones incorrectos.\n",
    "3. **Optimización del Rendimiento del Modelo**: Transformar los datos a una escala común y eliminar características irrelevantes puede mejorar significativamente la eficiencia y la precisión del modelo.\n",
    "4. **Manejo de Valores Faltantes**: Los valores faltantes pueden llevar a resultados incorrectos si no se manejan adecuadamente. El preprocesamiento permite abordar este problema de manera sistemática.\n",
    "\n",
    "## Pasos de Preprocesamiento\n",
    "\n",
    "### Paso 1: Cargar los Datasets\n",
    "\n",
    "Cargamos los datasets utilizando `pandas` para poder trabajar con ellos en forma de dataframes.\n",
    "\n",
    "### Paso 2: Inspeccionar los Datos\n",
    "\n",
    "Inspeccionamos los datos para entender su estructura y contenido. Esto nos permite identificar posibles duplicados, valores faltantes e inconsistencias. Utilizamos funciones como `info()` para obtener información sobre el número de entradas, el tipo de datos y la cantidad de valores no nulos en cada columna, y `head()` para ver las primeras filas de cada dataset y entender mejor su contenido.\n",
    "\n",
    "### Paso 3: Eliminar Duplicados\n",
    "\n",
    "Eliminamos cualquier registro duplicado en los dataframes utilizando el método `drop_duplicates()`. Esto es crucial para asegurar que los datos no contengan redundancias que puedan sesgar los resultados del modelo.\n",
    "\n",
    "### Paso 4: Normalización\n",
    "\n",
    "Normalizamos las coordenadas de las cajas delimitadoras para asegurarnos de que estén en un rango consistente. Esto se hace utilizando `MinMaxScaler` para escalar las coordenadas de las cajas delimitadoras a un rango de [0, 1]. La normalización es importante para que los algoritmos de Machine Learning, especialmente aquellos sensibles a la escala de los datos, funcionen correctamente.\n",
    "\n",
    "### Paso 5: Verificar Correspondencia entre Imágenes y Anotaciones\n",
    "\n",
    "Verificamos que todas las imágenes tengan anotaciones correspondientes. Esto implica comprobar que cada imagen en los datasets de prueba y validación tenga al menos una anotación asociada. Identificamos y eliminamos cualquier imagen que no tenga anotaciones correspondientes para asegurar la coherencia de los datos.\n",
    "\n",
    "### Paso 6: Guardar los Datasets Preprocesados\n",
    "\n",
    "Guardamos los datasets preprocesados en archivos CSV para su uso posterior en el entrenamiento del modelo. Esto asegura que los datos estén listos y disponibles en un formato adecuado cuando procedamos con el entrenamiento del modelo de detección de objetos.\n",
    "\n",
    "## Resumen\n",
    "\n",
    "El preprocesamiento de datos es una etapa esencial en el pipeline de Machine Learning que asegura la calidad y la integridad de los datos utilizados para entrenar modelos. A través de la carga, inspección, eliminación de duplicados, normalización, verificación de correspondencia y guardado de los datasets, hemos preparado nuestros datos para el siguiente paso: el entrenamiento del modelo de detección de objetos. Estas técnicas aseguran que los datos estén en una forma óptima para el modelado, lo que lleva a modelos más precisos y robustos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b52260-7770-42fd-9839-f5989d7e0f01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
